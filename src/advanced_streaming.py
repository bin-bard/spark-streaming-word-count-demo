#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Spark Streaming Advanced Demo - Windowing & Top Words
=====================================================

Demo nÃ¢ng cao vá»›i windowing operations vÃ  top words analysis.
Hiá»ƒn thá»‹ top 5 tá»« xuáº¥t hiá»‡n nhiá»u nháº¥t trong sliding window.

TÃ¡c giáº£: NhÃ³m Big Data Applications
NgÃ y táº¡o: 2024
"""

from pyspark import SparkContext
from pyspark.streaming import StreamingContext
import sys

def create_streaming_context():
    """
    Táº¡o vÃ  cáº¥u hÃ¬nh StreamingContext vá»›i checkpoint
    
    Returns:
        StreamingContext: Context Ä‘á»ƒ xá»­ lÃ½ streaming
    """
    # Táº¡o SparkContext vá»›i tÃªn á»©ng dá»¥ng
    sc = SparkContext("local[2]", "AdvancedWordCountStreaming")
    sc.setLogLevel("WARN")  # Giáº£m log Ä‘á»ƒ dá»… quan sÃ¡t
    
    # Táº¡o StreamingContext vá»›i batch interval 5 giÃ¢y
    ssc = StreamingContext(sc, 5)
    
    # Thiáº¿t láº­p checkpoint Ä‘á»ƒ lÆ°u trá»¯ state (cáº§n cho windowing)
    ssc.checkpoint("checkpoint")
    
    return ssc

def process_windowed_word_count(ssc, hostname="localhost", port=9999):
    """
    Xá»­ lÃ½ word count vá»›i windowing vÃ  top words analysis
    
    Args:
        ssc: StreamingContext
        hostname: Hostname cá»§a socket server
        port: Port cá»§a socket server
    """
    try:
        # Táº¡o DStream tá»« socket
        lines = ssc.socketTextStream(hostname, port)
        
        # Xá»­ lÃ½ cÆ¡ báº£n: tÃ¡ch tá»« vÃ  táº¡o pairs
        words = lines.flatMap(lambda line: line.split(" "))
        word_pairs = words.map(lambda word: (word.lower().strip(), 1))
        
        # ğŸ¯ WINDOWING OPERATIONS
        # Sliding window: 30 giÃ¢y, slide má»—i 10 giÃ¢y
        windowed_word_counts = word_pairs.reduceByKeyAndWindow(
            lambda x, y: x + y,      # HÃ m reduce
            lambda x, y: x - y,      # HÃ m inverse reduce (Ä‘á»ƒ tá»‘i Æ°u)
            windowDuration=30,       # Window size: 30 giÃ¢y
            slideDuration=10         # Slide interval: 10 giÃ¢y
        )
        
        # ğŸ† TOP WORDS ANALYSIS
        def get_top_words(time, rdd):
            """Láº¥y vÃ  hiá»ƒn thá»‹ top 5 tá»« trong window hiá»‡n táº¡i"""
            try:
                # Lá»c bá» tá»« rá»—ng vÃ  sáº¯p xáº¿p theo count giáº£m dáº§n
                top_words = rdd.filter(lambda x: len(x[0]) > 0) \
                              .filter(lambda x: x[0] != '') \
                              .takeOrdered(5, key=lambda x: -x[1])
                
                if top_words:
                    print(f"\nğŸ† TOP 5 Tá»ª TRONG WINDOW 30 GIÃ‚Y (táº¡i {time})")
                    print("=" * 50)
                    for i, (word, count) in enumerate(top_words, 1):
                        print(f"{i}. {word:15} -> {count:3} láº§n")
                    print("=" * 50)
                else:
                    print(f"\nğŸ“­ KhÃ´ng cÃ³ dá»¯ liá»‡u trong window (táº¡i {time})")
                    
            except Exception as e:
                print(f"âŒ Lá»—i khi xá»­ lÃ½ top words: {e}")
        
        # Ãp dá»¥ng hÃ m phÃ¢n tÃ­ch cho má»—i window
        windowed_word_counts.foreachRDD(get_top_words)
        
        # ğŸ“Š REAL-TIME STATS
        def print_stats(time, rdd):
            """In thá»‘ng kÃª real-time"""
            try:
                total_words = rdd.map(lambda x: x[1]).reduce(lambda x, y: x + y) if not rdd.isEmpty() else 0
                unique_words = rdd.count()
                
                print(f"\nğŸ“Š THá»NG KÃŠ WINDOW (táº¡i {time})")
                print(f"   ğŸ“ Tá»•ng sá»‘ tá»«: {total_words}")
                print(f"   ğŸ”¤ Tá»« duy nháº¥t: {unique_words}")
                print(f"   ğŸ“ˆ Tá»· lá»‡ láº·p: {total_words/unique_words:.2f}" if unique_words > 0 else "   ğŸ“ˆ Tá»· lá»‡ láº·p: N/A")
                
            except Exception as e:
                print(f"âŒ Lá»—i khi tÃ­nh thá»‘ng kÃª: {e}")
        
        windowed_word_counts.foreachRDD(print_stats)
        
        return windowed_word_counts
        
    except Exception as e:
        print(f"âŒ Lá»—i khi xá»­ lÃ½ stream: {e}")
        return None

def main():
    """
    HÃ m chÃ­nh Ä‘á»ƒ cháº¡y demo nÃ¢ng cao
    """
    print("ğŸš€ Spark Streaming Advanced Demo - Windowing & Analytics")
    print("=" * 65)
    print("ğŸ¯ TÃ­nh nÄƒng nÃ¢ng cao:")
    print("   âœ… Sliding Window (30s window, 10s slide)")
    print("   âœ… Top 5 tá»« phá»• biáº¿n nháº¥t trong má»—i window")
    print("   âœ… Thá»‘ng kÃª real-time (tá»•ng tá»«, tá»« duy nháº¥t)")
    print("   âœ… Inverse reduce Ä‘á»ƒ tá»‘i Æ°u performance")
    print("=" * 65)
    print("ğŸ“‹ HÆ°á»›ng dáº«n:")
    print("1. Má»Ÿ terminal khÃ¡c vÃ  cháº¡y: nc -lk 9999")
    print("2. GÃµ nhiá»u cÃ¢u liÃªn tá»¥c trong 30 giÃ¢y")
    print("3. Quan sÃ¡t top words vÃ  thá»‘ng kÃª má»—i 10 giÃ¢y")
    print("4. Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng")
    print("=" * 65)
    print("ğŸ’¡ VÃ­ dá»¥ input Ä‘á»ƒ test:")
    print("   'spark streaming is awesome'")
    print("   'spark processing real time data'")  
    print("   'streaming with spark is fun'")
    print("=" * 65)
    
    # Táº¡o StreamingContext
    ssc = create_streaming_context()
    
    try:
        # Xá»­ lÃ½ windowed word count
        word_counts = process_windowed_word_count(ssc)
        
        if word_counts is not None:
            # Báº¯t Ä‘áº§u streaming context
            ssc.start()
            
            print("âœ… Advanced Streaming Ä‘Ã£ khá»Ÿi Ä‘á»™ng...")
            print("â° Äang chá» dá»¯ liá»‡u... (káº¿t quáº£ sáº½ xuáº¥t hiá»‡n sau 10 giÃ¢y)")
            print("ğŸ¯ GÃµ nhiá»u cÃ¢u Ä‘á»ƒ tháº¥y top words analysis!")
            
            # Chá» cho Ä‘áº¿n khi bá»‹ terminate
            ssc.awaitTermination()
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ Äang dá»«ng streaming...")
        ssc.stop(stopSparkContext=True, stopGraceFully=True)
        print("âœ… ÄÃ£ dá»«ng thÃ nh cÃ´ng!")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        ssc.stop(stopSparkContext=True, stopGraceFully=True)

if __name__ == "__main__":
    main()